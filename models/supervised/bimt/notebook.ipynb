{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse, Circle\n",
    "import numpy as np\n",
    "import torch\n",
    "from model import BioMLP\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "n_sample = 500\n",
    "X, y = make_moons(n_samples=n_sample, noise=0.1)\n",
    "color = ['red', 'blue']\n",
    "\n",
    "for i in range(n_sample):\n",
    "    plt.scatter(X[i,0],X[i,1],color=color[y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7860a1eb30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase = \"toy_swap\"\n",
    "\n",
    "plot_log = 50#50\n",
    "save_log = 100\n",
    "\n",
    "steps = 10001\n",
    "# create dataset\n",
    "\n",
    "d_in = 2\n",
    "d_out = 2\n",
    "\n",
    "n_sample = 200\n",
    "X, y = make_moons(n_samples=n_sample, noise=0.1)\n",
    "X = torch.tensor(X, dtype=torch.float, requires_grad=True)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "n_sample = 200\n",
    "X_test, y_test = make_moons(n_samples=n_sample, noise=0.1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float, requires_grad=True)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "width = 20\n",
    "depth = 3\n",
    "shp = [d_in, 20, 20, d_out]\n",
    "\n",
    "\n",
    "seed = 2\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "#torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = len(os.listdir('./saved_models'))\n",
    "os.mkdir(f\"./saved_models/{indx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BioMLP(shp=[2,20,20,2])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.002, weight_decay=0.0)\n",
    "#steps = 10000\n",
    "log = 200\n",
    "lamb = 0.001\n",
    "swap_log = 200\n",
    "\n",
    "\n",
    "for step in range(steps):\n",
    "    \n",
    "    # small lambda first, then large lambda, then small lambda\n",
    "    if step == 5000:\n",
    "        lamb = 0.01\n",
    "        \n",
    "    if step == 15000:\n",
    "        lamb = 0.001\n",
    "    \n",
    "    CEL = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    pred  = model(X)\n",
    "    loss = CEL(pred, y)\n",
    "    #print((torch.argmax(pred, dim=1) == y).float())\n",
    "    acc = torch.mean((torch.argmax(pred, dim=1) == y).float())\n",
    "    \n",
    "    \n",
    "    pred_test  = model(X_test)\n",
    "    loss_test = CEL(pred_test, y_test)\n",
    "    acc_test = torch.mean((torch.argmax(pred_test, dim=1) == y_test).float())\n",
    "    \n",
    "    reg = model.get_cc(weight_factor=1.)\n",
    "    total_loss = loss + lamb*reg\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % log == 0:\n",
    "        print(\"step = %d | total loss: %.2e | train loss: %.2e | test loss %.2e | train acc : %.2f | test acc : %.2f | reg: %.2e \"%(step, total_loss.detach().numpy(), loss.detach().numpy(), loss_test.detach().numpy(), acc.detach().numpy(), acc_test.detach().numpy(), reg.detach().numpy()))\n",
    "    \n",
    "    if (step+1) % swap_log == 0:\n",
    "        #pass\n",
    "        model.relocate()\n",
    "\n",
    "    if step % save_log == 0:\n",
    "        torch.save(model.state_dict(), f\"saved_models/{indx}/model_{step}.pt\")\n",
    "\n",
    "\n",
    "    if step % plot_log == 0:\n",
    "        plt.figure(figsize=(3, 7)) \n",
    "\n",
    "        plt.subplot(2,1,1)\n",
    "\n",
    "        N = 2\n",
    "        s = 1/(2*max(shp))\n",
    "        for j in range(len(shp)):\n",
    "            N = shp[j]\n",
    "            for i in range(N):\n",
    "                circle = Ellipse((1/(2*N)+i/N, 0.1*j), s, s/10*((len(shp)-1)+0.4), color='black')\n",
    "                plt.gca().add_patch(circle)\n",
    "\n",
    "\n",
    "        plt.ylim(-0.02,0.1*(len(shp)-1)+0.02)\n",
    "        plt.xlim(-0.02,1.02)\n",
    "\n",
    "        ii = 0\n",
    "        for p in model.parameters():\n",
    "\n",
    "\n",
    "            if len(p.shape) == 2:\n",
    "                p_shp = p.shape\n",
    "                p = p/torch.abs(p).max()\n",
    "                for i in range(p_shp[0]):\n",
    "                    for j in range(p_shp[1]):\n",
    "                        if p[i,j] > 0:\n",
    "                            plt.plot([1/(2*p_shp[0])+i/p_shp[0], 1/(2*p_shp[1])+j/p_shp[1]], [0.1*(ii+1),0.1*ii], lw=1*np.abs(p[i,j].detach().numpy()), color=\"blue\")\n",
    "                        else:\n",
    "                            plt.plot([1/(2*p_shp[0])+i/p_shp[0], 1/(2*p_shp[1])+j/p_shp[1]], [0.1*(ii+1),0.1*ii], lw=1*np.abs(p[i,j].detach().numpy()), color=\"red\")\n",
    "\n",
    "                formulas = [\"Class 1\", \"Class 2\"]\n",
    "                if ii == 0:\n",
    "                    for j in range(p_shp[1]):\n",
    "                        plt.text(1/(2*p_shp[1])+j/p_shp[1]-0.05, 0.1*ii-0.04, \"$x_{}$\".format(model.in_perm[j].long()+1), fontsize=15)\n",
    "                ii += 1\n",
    "\n",
    "\n",
    "        for j in range(p_shp[0]):\n",
    "            plt.text(1/(2*p_shp[0])+j/p_shp[0]-0.15, 0.1*ii+0.02, formulas[model.out_perm[j].long()], fontsize=15)\n",
    "\n",
    "        plt.gca().axis('off')\n",
    "        plt.title(\"step={}\".format(step), fontsize=15, y=1.1)\n",
    "\n",
    "\n",
    "        plt.subplot(2,1,2)\n",
    "\n",
    "\n",
    "        start_x = X[:,0].min()-0.1\n",
    "        end_x = X[:,0].max()+0.1\n",
    "        start_y = X[:,1].min()-0.1\n",
    "        end_y = X[:,1].max()+0.1\n",
    "        n_values = 30\n",
    "\n",
    "        x_vals = np.linspace(start_x.detach().numpy(), end_x.detach().numpy(), n_values)\n",
    "        y_vals = np.linspace(start_y.detach().numpy(), end_y.detach().numpy(), n_values)\n",
    "        XX, YY = np.meshgrid(x_vals, y_vals)\n",
    "        pred = model(torch.tensor([XX.reshape(-1,), YY.reshape(-1,)], dtype=torch.float).permute(1,0))\n",
    "        pred = pred[:,1] - pred[:,0]\n",
    "\n",
    "        #ZZ = np.sqrt(XX**2 + YY**2)\n",
    "\n",
    "        cp = plt.contourf(XX, YY, pred.reshape(n_values,n_values).detach().numpy(), [-100,0.,100.], colors=[\"green\",\"orange\"], alpha=0.2)\n",
    "        #plt.colorbar(cp)\n",
    "        color = ['green', 'orange']\n",
    "\n",
    "        for i in range(n_sample):\n",
    "            plt.scatter(X[i,0].detach().numpy(),X[i,1].detach().numpy(),color=color[y[i]])\n",
    "\n",
    "\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.xlabel(r\"$x_1$\", fontsize=15)\n",
    "        plt.ylabel(r\"$x_2$\", fontsize=15)\n",
    "        #plt.show()\n",
    "    \n",
    "        plt.savefig(\"figures/{0:05d}.png\".format(step))\n",
    "        \n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
