{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../../../')\n",
    "\n",
    "from experiments.assumptions.degeneracy.script import eigenvalue_result, eigenvalue_results_large, plot_rank_train, rank_over_training\n",
    "from models.supervised.mlp.model import MLP\n",
    "from models.supervised.bimt.model import BioMLP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb233b384d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: vanilla, Epoch: 5\n",
      "Size: vanilla, Epoch: 60\n",
      "Size: vanilla, Epoch: 80\n",
      "Size: vanilla, Epoch: 199\n"
     ]
    }
   ],
   "source": [
    "mode = \"moon\"\n",
    "model_name = \"mlp\"\n",
    "size = \"2_wide\"\n",
    "models_path = f\"../../../models/supervised/{model_name}/saved_models\"\n",
    "if size == \"overfit\":\n",
    "\twith open(f'{models_path}/2_wide/{mode}/dataset.pkl', 'rb') as f:\n",
    "\t\tdataset = pkl.load(f)\n",
    "else:\n",
    "\twith open(f'{models_path}/{size}/{mode}/dataset.pkl', 'rb') as f:\n",
    "\t\tdataset = pkl.load(f)\n",
    "\n",
    "for size in [\"mixup_vanilla\", \"vanilla\",  \"overfit\", \"2_wide\"]:\n",
    "\tif size == \"overfit\":\n",
    "\t\tepochs = [60, 80, 199, 9999, 999, 5]\n",
    "\telse:\n",
    "\t\tepochs = [5, 60, 80, 199]\n",
    "\tfor epoch in epochs:\n",
    "\t\tif size == \"vanilla\" or size == \"mixup_vanilla\":\n",
    "\t\t\tmodel = MLP(2,7,10,2)\n",
    "\t\telif size == \"overfit\":\n",
    "\t\t\tmodel = MLP(2,7,2,1)\n",
    "\t\telif size == \"2_wide\":\n",
    "\t\t\tmodel = MLP(2,7,2,2)\n",
    "\t\tprint(f\"Size: {size}, Epoch: {epoch}\")\n",
    "\t\tmodel.eval()\n",
    "\t\tmodel.load_state_dict(torch.load(f'{models_path}/{size}/{mode}/model_{epoch}.pth'))\n",
    "\t\tif size == \"overfit\":\n",
    "\t\t\tmodel.num_layers -= 1\n",
    "\t\t\tmodel.layers = model.layers[:-1]\n",
    "\t\tsave_path = f\"figures/{model_name}/{mode}/{size}/{epoch}/\"\n",
    "\t\teigenvalue_result(dataset.X, model, N=50, labels=dataset.y, wrt=\"output_wise\", sigma=0.05, precision=7, save_path=save_path)\n",
    "\t\teigenvalue_result(dataset.X, model, N=50, labels=dataset.y, wrt=\"layer_wise\", sigma=0.05, precision=7, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"blobs\"\n",
    "model_name = \"mlp\"\n",
    "size = \"vanilla\"\n",
    "with open(f'{models_path}/{size}/{mode}/dataset.pkl', 'rb') as f:\n",
    "\tdataset = pkl.load(f)\n",
    "epochs = [5, 60, 80, 199]\n",
    "\n",
    "for size in [\"vanilla\"]:\n",
    "\tfor epoch in epochs:\n",
    "\t\tif size == \"vanilla\":\n",
    "\t\t\tmodel = MLP(2,7,4,4)\n",
    "\t\tprint(f\"Size: {size}, Epoch: {epoch}\")\n",
    "\t\tmodel.eval()\n",
    "\t\tmodel.load_state_dict(torch.load(f'{models_path}/{size}/{mode}/model_{epoch}.pth'))\n",
    "\t\tsave_path = f\"figures/{model_name}/{mode}/{size}/{epoch}/\"\n",
    "\t\teigenvalue_result(dataset.X, model, N=50, labels=dataset.y, wrt=\"output_wise\", sigma=0.05, precision=7, save_path=save_path)\n",
    "\t\teigenvalue_result(dataset.X, model, N=50, labels=dataset.y, wrt=\"layer_wise\", sigma=0.05, precision=7, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:32<00:00,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "mode=\"moon\"\n",
    "model_name = \"bimt\"\n",
    "size = \"vanilla\"\n",
    "\n",
    "model = BioMLP(shp=[2,20,20,2])\n",
    "models_path = f\"../../../models/supervised/{model_name}/saved_models\"\n",
    "\n",
    "res_q_25, res_med, res_q_75 = [], [], []\n",
    "with open(f'{models_path}/{size}/{mode}/dataset.pkl', 'rb') as f:\n",
    "\tdataset = pkl.load(f)\n",
    "\n",
    "for epoch in tqdm(range(0, 10000, 100)):\n",
    "\tmodel.load_state_dict(torch.load(f'{models_path}/{size}/{mode}/model_{epoch}.pth'))\n",
    "\tmodel.eval()\n",
    "\tsave_path = f\"figures/{model_name}/{mode}/{size}/{epoch}/\"\n",
    "\t\n",
    "\tq_25, med, q_75 = eigenvalue_results_large(dataset.X, model, N=50, wrt=\"output_wise\", sigma=0.05, precision=7, save_path=save_path)\n",
    "\tres_q_25.append(q_25)\n",
    "\tres_med.append(med)\n",
    "\tres_q_75.append(q_75)\n",
    "\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rank_train(res_q_25, res_med, res_q_75, savepath=f\"figures/{model_name}/{mode}/{size}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:35<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "mode=\"moon\"\n",
    "model_name = \"mlp\"\n",
    "size = \"overfit\"\n",
    "\n",
    "\n",
    "models_path = f\"../../../models/supervised/{model_name}/saved_models\"\n",
    "\n",
    "res_q_25, res_med, res_q_75 = [], [], []\n",
    "with open(f'{models_path}/2_wide/{mode}/dataset.pkl', 'rb') as f:\n",
    "\tdataset = pkl.load(f)\n",
    "\n",
    "for epoch in tqdm(range(0, 10000, 100)):\n",
    "\tmodel = MLP(2,7,2,1)\n",
    "\n",
    "\tmodel.load_state_dict(torch.load(f'{models_path}/{size}/{mode}/model_{epoch}.pth'))\n",
    "\tif size == \"overfit\":\n",
    "\t\tmodel.num_layers -= 1\n",
    "\t\tmodel.layers = model.layers[:-1]\n",
    "\tmodel.eval()\n",
    "\tsave_path = f\"figures/{model_name}/{mode}/{size}/{epoch}/\"\n",
    "\t\n",
    "\tq_25, med, q_75 = rank_over_training(dataset.X, model, N=50, wrt=\"output_wise\", sigma=0.05, precision=7)\n",
    "\tres_q_25.append(q_25)\n",
    "\tres_med.append(med)\n",
    "\tres_q_75.append(q_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rank_train(res_q_25, res_med, res_q_75, savepath=f\"figures/{model_name}/{mode}/{size}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
