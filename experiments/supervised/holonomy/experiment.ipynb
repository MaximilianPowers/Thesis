{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "sys.path.append('../../../')\n",
    "\n",
    "#from experiments.supervised.product_manifold.script import main, _plot_clusters, _plot_holonomy_dist, _plot_holonomy_surface\n",
    "from models.supervised.mlp.model import MLP\n",
    "from models.unsupervised.vae.model import VAE, Encoder, Decoder\n",
    "from models.supervised.bimt.model import BioMLP\n",
    "from experiments.supervised.holonomy.script import main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa1dac2ec10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = \"vanilla\"\n",
    "mode = \"moon\"\n",
    "model_name = \"mlp\"\n",
    "epoch = 199\n",
    "#model = BioMLP(shp=[2,20,20,2])\n",
    "model = MLP(2,7,10,2)\n",
    "models_path = f\"../../../models/supervised/{model_name}/saved_models\"\n",
    "\n",
    "with open(f'{models_path}/{size}/{mode}/dataset.pkl', 'rb') as f:\n",
    "\tdataset = pkl.load(f)\n",
    "\n",
    "full_path = f'{models_path}/{size}/{mode}/model_{epoch}.pth'\n",
    "model.load_state_dict(torch.load(full_path))\n",
    "if size == \"overfit\":\n",
    "\tmodel.num_layers -= 1\n",
    "\tmodel.layers = model.layers[:-1]\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1\n",
    "quantile = 0.9\n",
    "tol = 1e-5\n",
    "save_path = f\"figures/{model_name}/{mode}/{size}/{epoch}\"\n",
    "N = 20\n",
    "holonomy_manifolds, loop_point_manifolds, transformation_matrix = main(model, dataset, N, sigma, quantile, tol, save_path, MIN_SIZE=10, wrt=\"output_wise\", plot_hol=True, plot_graph=True, plot_group=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import from_numpy\n",
    "import random\n",
    "from collections import deque, defaultdict\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from riemannian_geometry.differential_geometry.curvature import batch_vectorised_christoffel_symbols\n",
    "from riemannian_geometry.computations.pullback_metric import pullback_holonomy\n",
    "from riemannian_geometry.differential_geometry.holonomy import product_manifold\n",
    "from riemannian_geometry.computations.riemann_metric import LocalDiagPCA\n",
    "from riemannian_geometry.computations.sample import sample_points_heat_kernel\n",
    "from riemannian_geometry.differential_geometry.curvature import batch_curvature\n",
    "import time\n",
    "from torch.func import vmap, jacfwd, jacrev\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def compute_jacobian_multi_layer(layer_func, X, dim_in, dim_out):\n",
    "    if dim_out >= dim_in:\n",
    "        jacobian = vmap(jacfwd(layer_func))(X)\n",
    "    else:\n",
    "        jacobian = vmap(jacrev(layer_func))(X)\n",
    "    return jacobian\n",
    "\n",
    "def batch_form_pullback(start, end, jacobian, form):\n",
    "    jacobian_batch = jacobian[start:end]\n",
    "    form_batch = form[start:end]\n",
    "    return np.einsum('lai,lbj,lck,labc->lijk', jacobian_batch, jacobian_batch, jacobian_batch, form_batch)\n",
    "\n",
    "def pullback_holonomy(model, activations, N=20, sigma=0.05, method=\"manifold\", wrt=\"output_wise\", normalised=False):\n",
    "    activations_np = [activation.detach().numpy() for activation in activations]\n",
    "    manifold = LocalDiagPCA(activations_np[-1], sigma=sigma, rho=1e-5)\n",
    "    \n",
    "\n",
    "    xy_grid = sample_points_heat_kernel(activations_np[0], num_samples=N**2, connect_components=2, t=1/sigma)\n",
    "    surface_tensor = torch.from_numpy(xy_grid).float()\n",
    "    model.forward(surface_tensor, save_activations=True)\n",
    "    surfaces = model.get_activations()\n",
    "    _xy_grids = [surface.detach().numpy() for surface in surfaces]\n",
    "    xy_grid = _xy_grids[-1]\n",
    "\n",
    "    output_g, output_dg, output_ddg = manifold.metric_tensor(xy_grid.transpose(), nargout=3)\n",
    "    _, output_Ricci, _ = batch_curvature(output_g, output_dg, output_ddg)\n",
    "    \n",
    "    start = time.time()\n",
    "    dim_in = model.layers[0].in_features\n",
    "    dim_out = model.layers[-1].out_features\n",
    "    xy_grid = _xy_grids[0]\n",
    "\n",
    "    xy_grid_tensor = torch.from_numpy(xy_grid).float()\n",
    "    def forward_layers(x):\n",
    "        return model.forward_layers(x, 0)\n",
    "    dim_out = model.layers[-1].out_features\n",
    "    jacobian = compute_jacobian_multi_layer(forward_layers, xy_grid_tensor, dim_in, dim_out)\n",
    "    end = time.time()\n",
    "    print(\"Jacobian computed in {} seconds\".format(end-start))\n",
    "\n",
    "    start = time.time()\n",
    "    jacobian = jacobian.detach().numpy()\n",
    "    end = time.time()\n",
    "    print(\"Jacobian converted to numpy in {} seconds\".format(end-start))  \n",
    "\n",
    "    start = time.time()\n",
    "    g_pullback = np.einsum('lai,lbj,lab->lij', jacobian, jacobian, output_g)\n",
    "    end = time.time()\n",
    "    print(\"Pullback metric computed in {} seconds\".format(end-start))\n",
    "\n",
    "    start = time.time()\n",
    "    n = g_pullback.shape[0]\n",
    "    D = g_pullback.shape[1]\n",
    "    dg_batches = []\n",
    "    batch_size = n // D\n",
    "    n_batches = n // batch_size\n",
    "    remainder = n % batch_size\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for i in range(n_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = (i + 1) * batch_size\n",
    "            future = executor.submit(batch_form_pullback, start_idx, end_idx, jacobian, output_dg)\n",
    "            futures.append(future)\n",
    "        if remainder > 0:\n",
    "            start_idx = n_batches * batch_size\n",
    "            end_idx = n  # Go until the end to include the remainder\n",
    "            future = executor.submit(batch_form_pullback, start_idx, end_idx, jacobian, output_dg)\n",
    "            futures.append(future)\n",
    "        for future in futures:\n",
    "            dg_batches.append(future.result())\n",
    "    dg_pullback = np.concatenate(dg_batches, axis=0)\n",
    "    end = time.time()\n",
    "    print(\"Pullback differential computed in {} seconds\".format(end-start))\n",
    "\n",
    "    start = time.time()\n",
    "    Ricci_pullback = np.einsum('Nai,Nbj,Nab->Nij', jacobian, jacobian, output_Ricci)\n",
    "    end = time.time()\n",
    "    print(\"Pullback Ricci computed in {} seconds\".format(end-start))\n",
    "\n",
    "    return g_pullback, dg_pullback, Ricci_pullback, xy_grid\n",
    "\n",
    "\n",
    "def find_cycles_random_walk(graph, num_cycles, max_walk_length=100):\n",
    "    cycles = []\n",
    "    vertices = list(graph.nodes())\n",
    "    \n",
    "    while len(cycles) < num_cycles:\n",
    "        # Step 1: Choose a random starting vertex\n",
    "        start_vertex = random.choice(vertices)\n",
    "        \n",
    "        # Steps 2-5: Perform the random walk to find a cycle\n",
    "        visited = set()\n",
    "        walk = deque()\n",
    "        current_vertex = start_vertex\n",
    "        last_vertex = None  # Keep track of the last visited vertex\n",
    "        \n",
    "        for _ in range(max_walk_length):\n",
    "            visited.add(current_vertex)\n",
    "            walk.append(current_vertex)\n",
    "            \n",
    "            # Step 3: Move to a randomly chosen neighbor, avoiding the last visited vertex\n",
    "            neighbors = [n for n in graph.neighbors(current_vertex) if n != last_vertex]\n",
    "            if not neighbors:\n",
    "                break  # No valid neighbors to move to; terminate this walk\n",
    "                \n",
    "            last_vertex, current_vertex = current_vertex, random.choice(neighbors)\n",
    "            \n",
    "            # Step 4: Check if we've found a cycle\n",
    "            if current_vertex == start_vertex:\n",
    "                cycle = list(walk)\n",
    "                cycles.append(cycle)\n",
    "                break\n",
    "            \n",
    "            # Terminate the walk if it's a repeat vertex but not the start (not a simple cycle)\n",
    "            if current_vertex in visited and current_vertex != start_vertex:\n",
    "                break\n",
    "\n",
    "    return cycles\n",
    "\n",
    "def parallel_transport(P, X, Christoffel):\n",
    "    \"\"\"\n",
    "    Approximate the parallel transport of a vector X along a path P with given Christoffel symbols.\n",
    "    \n",
    "    Parameters:\n",
    "    - P: list of numpy arrays, representing the points on the path\n",
    "    - X: numpy array, representing the initial vector at P[0]\n",
    "    - Christoffel: list of 3D numpy arrays, representing the Christoffel symbols at each point P[i]\n",
    "    \n",
    "    Returns:\n",
    "    - X_transported: numpy array, representing the parallel transported vector at the end of the path\n",
    "    \"\"\"\n",
    "    # Initialize the transported vector as X\n",
    "    X_transported = np.copy(X)\n",
    "    \n",
    "    # Iterate over the path\n",
    "    for i in range(len(P) - 1):\n",
    "        # Compute the finite difference between adjacent points\n",
    "        delta_x = P[i + 1] - P[i]\n",
    "        \n",
    "        # Get the Christoffel symbols at the current point\n",
    "        Gamma = Christoffel[i]\n",
    "        \n",
    "        # Update the transported vector using the Christoffel symbols and the finite difference\n",
    "        for k in range(len(X)):\n",
    "            delta_X_k = -np.sum(Gamma[k, :, :] * X_transported[:, np.newaxis] * delta_x[np.newaxis, :])\n",
    "            X_transported[k] += delta_X_k\n",
    "    return X_transported\n",
    "\n",
    "def holonomy_product_manifold(manifolds, metric, form, surface, num_cycles=None):\n",
    "    if num_cycles is None:\n",
    "        num_cycles = 10000\n",
    "    holonomy_manifolds = []\n",
    "    loop_point_manifolds = []\n",
    "    transformation_matrix = []\n",
    "    ranks = []\n",
    "    for manifold in manifolds:\n",
    "        point_cloud_metric = metric[list(manifold.nodes)]\n",
    "        point_cloud_surface = surface[list(manifold.nodes)]\n",
    "        point_cloud_form = form[list(manifold.nodes)]\n",
    "        mappable_dict = {v: indx for indx, v in enumerate(list(manifold.nodes))}\n",
    "        rank = int(manifold.nodes[list(manifold.nodes)[0]][\"rank\"])\n",
    "        ranks.append(rank)\n",
    "        print(f\"Rank {rank}\")\n",
    "        if rank != 0:\n",
    "            holonomy_manifold, loop_points, transformation_manifold = holonomy(manifold, point_cloud_metric, point_cloud_form, point_cloud_surface, mappable_dict, rank, num_cycles=num_cycles)\n",
    "            holonomy_manifolds.append(holonomy_manifold)\n",
    "            loop_point_manifolds.append(loop_points)\n",
    "            transformation_matrix.append(transformation_manifold)\n",
    "        else:\n",
    "            holonomy_manifolds.append([])\n",
    "            loop_point_manifolds.append([])\n",
    "            transformation_matrix.append([])\n",
    "\n",
    "    return holonomy_manifolds, loop_point_manifolds, transformation_matrix, ranks\n",
    "\n",
    "def filter_eigs(g, dg, K):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(g)\n",
    "    sorted_indices = np.argsort(eigenvalues, axis=-1)\n",
    "\n",
    "    top_k_indices = sorted_indices[:, -K:]\n",
    "    V = np.take_along_axis(eigenvectors, np.expand_dims(top_k_indices, axis=2), axis=1)\n",
    "\n",
    "    # Step 3: Compute the reduced metric \\tilde{g}\n",
    "    g_tilde = np.einsum('nia,njb,nab->nij', V, V, g)\n",
    "\n",
    "    # Step 4: Compute the differential of the reduced metric \\tilde{g}, d\\tilde{g}\n",
    "    d_g_tilde = np.einsum('nia,njb,nkc,nabc->nijk', V, V, V, dg)\n",
    "    return V, g_tilde, d_g_tilde\n",
    "\n",
    "\n",
    "def create_dict_from_lists(list1, list2):\n",
    "    # Initialize a defaultdict to store the sum and count for each unique key\n",
    "    sum_count_dict = defaultdict(lambda: {'sum': 0, 'count': 0})\n",
    "    \n",
    "    # Iterate over the sublists in list1 and list2\n",
    "    for sublist1, sublist2 in zip(list1, list2):\n",
    "        for key, value in zip(sublist1, sublist2):\n",
    "            sum_count_dict[key]['sum'] += value\n",
    "            sum_count_dict[key]['count'] += 1\n",
    "    \n",
    "    # Create the final dictionary where the value is the mean for each key\n",
    "    mean_dict = {key: sum_count_dict[key]['sum'] / sum_count_dict[key]['count'] for key in sum_count_dict}\n",
    "    \n",
    "    return mean_dict\n",
    "\n",
    "def _plot_hol(holonomy_manifolds, save_path, ranks, wrt=\"output_wise\"):\n",
    "    iter_ = [indx for indx, h in enumerate(holonomy_manifolds) if len(h) > 0]\n",
    "    M = len(iter_)\n",
    "    fig, ax = plt.subplots(1, M, figsize=(M * 8, 8))\n",
    "    if M == 1:\n",
    "        ax = [ax]\n",
    "    for indx, i in enumerate(iter_):\n",
    "        ax[indx].hist(holonomy_manifolds[i], bins=100)\n",
    "        ax[indx].set_title(f\"Manifold {i} - Rank {ranks[i]}\")\n",
    "    fig.savefig(f\"{save_path}/_{wrt}_holonomy_hist.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def _plot_graph(loop_point_manifolds, holonomy_manifolds, subgraphs, pos, save_path, dataset, ranks, wrt=\"output_wise\"):\n",
    "\n",
    "    result = create_dict_from_lists(loop_point_manifolds, holonomy_manifolds)\n",
    "    combined_graph = nx.Graph()\n",
    "    for i in range(len(subgraphs)):\n",
    "        combined_graph.add_nodes_from(subgraphs[i].nodes)\n",
    "        for node in subgraphs[i].nodes:\n",
    "            combined_graph.nodes[node][\"cluster\"]=i\n",
    "        combined_graph.add_edges_from(subgraphs[i].edges)\n",
    "\n",
    "    M = len(subgraphs)+1\n",
    "    fig, ax = plt.subplots(1, M, figsize=(16*M, 12))\n",
    "    ax[0].scatter(dataset.X[:,0], dataset.X[:,1], c=dataset.y, cmap=plt.cm.viridis, s=20, edgecolors = 'red')\n",
    "    color = nx.draw_networkx_nodes(combined_graph, pos=pos, node_color=[combined_graph.nodes[node][\"cluster\"] for node in combined_graph.nodes], vmin=0, vmax=len(subgraphs), cmap=plt.cm.Accent, node_size=20, ax=ax[0])\n",
    "    nx.draw_networkx_edges(combined_graph, pos=pos, alpha=0.6, ax=ax[0])\n",
    "    plt.colorbar(color, ax=ax[0])\n",
    "    ax[0].set_title(\"Combined graph\")\n",
    "\n",
    "    for indx, subgraph in enumerate(subgraphs):\n",
    "        colors = [result.get(i, 0) for i in subgraph.nodes]\n",
    "        v_min = min(colors)\n",
    "        v_max = max(colors)\n",
    "        color = nx.draw_networkx_nodes(subgraph, pos=pos, node_color=colors, cmap=plt.cm.RdBu_r, node_size=20, vmin=v_min, vmax=v_max, ax=ax[indx+1])\n",
    "        nx.draw_networkx_edges(subgraphs[indx], pos=pos, alpha=0.6, ax=ax[indx+1])\n",
    "        plt.colorbar(color, ax=ax[indx+1])\n",
    "        ax[indx+1].set_title(f\"Manifold {indx} - Rank {ranks[indx]}\")\n",
    "\n",
    "    fig.savefig(f\"{save_path}/_{wrt}_holonomy_graph.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def _plot_holonomy_group(transformation_matrix, holonomy_manifolds, ranks, save_path, wrt=\"output_wise\"):\n",
    "    iter_ = [indx for indx, h in enumerate(holonomy_manifolds) if len(h) > 0]\n",
    "    M = len(iter_)\n",
    "    fig, ax = plt.subplots(2, M, figsize=(M * 8, 16))\n",
    "    if M == 1:\n",
    "        ax = [[ax[0]], [ax[1]]]\n",
    "    for indx, i in enumerate(iter_):\n",
    "        V = np.linalg.det(transformation_matrix[i])\n",
    "        ax[0][indx].hist(V[np.absolute(V) < 2].real, bins=100)\n",
    "        ax[0][indx].set_title(f\"Manifold {i} - Rank {ranks[i]}\")\n",
    "        ax[0][indx].set_xlabel('Determinant of Transformation Matrix')\n",
    "        ax[0][indx].set_ylabel('Frequency')\n",
    "        ax[0][indx].grid()\n",
    "\n",
    "        cosine_scores = []\n",
    "        sine_scores = []\n",
    "\n",
    "        for loop in holonomy_manifolds[0]:\n",
    "            loop = loop.real\n",
    "            sine_angle = np.sqrt(1 - loop ** 2)  # Since sin^2(theta) + cos^2(theta) = 1\n",
    "\n",
    "            cosine_scores.append(loop)\n",
    "            cosine_scores.append(-loop)\n",
    "            sine_scores.append(sine_angle)\n",
    "            sine_scores.append(-sine_angle)\n",
    "\n",
    "        ax[1][indx].scatter(cosine_scores, sine_scores, s=10)\n",
    "        ax[1][indx].set_xlim(-1.5, 1.5)\n",
    "        ax[1][indx].set_ylim(-1.5, 1.5)\n",
    "        ax[1][indx].set_xlabel('Cosine Scores')\n",
    "        ax[1][indx].set_ylabel('Sine Scores')\n",
    "        ax[1][indx].set_title('Holonomy Group Visualization')\n",
    "        # Set grids on ax[1][i]\n",
    "        ax[1][indx].grid()\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f\"{save_path}/_{wrt}_holonomy_group.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def main(model, dataset, N, sigma, quantile, tol, save_path, MIN_SIZE=None, wrt=\"output_wise\", plot_hol=False, plot_graph=False, plot_group=False):\n",
    "    if plot_hol or plot_graph or plot_group:\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "    if isinstance(dataset.X, torch.Tensor):\n",
    "        X = dataset.X.float()[:1000]\n",
    "    else:\n",
    "        X = from_numpy(dataset.X).float()\n",
    "    model.forward(X, save_activations=True)\n",
    "    activations = model.get_activations()\n",
    "    # In pullback_metric_christoffel, we force the Christoffel symbols to be normalised as we primarily care about the direction.\n",
    "    g_pullback, dg_pullback, Ricci_pullback, input_surface = pullback_holonomy(model, activations, N, wrt=wrt, method=\"manifold\", sigma=sigma, normalised=False) \n",
    "    print(f\"Pulled back\")\n",
    "    pos = {i: input_surface[i] for i in range(len(input_surface))}\n",
    "    subgraphs = product_manifold(Ricci_pullback, input_surface, g_pullback, \n",
    "        quantile=quantile, max_K=5, dataset=dataset, pos=pos, plot_V=False, \n",
    "        save_path=None, tol=tol, MIN_SIZE=MIN_SIZE, wrt=wrt)\n",
    "\n",
    "    holonomy_manifolds, loop_point_manifolds, transformation_matrix, ranks = holonomy_product_manifold(subgraphs, g_pullback, dg_pullback, input_surface)\n",
    "    #if plot_hol:\n",
    "    #    _plot_hol(holonomy_manifolds, save_path, ranks, wrt=wrt)\n",
    "    #if plot_graph:\n",
    "    #    _plot_graph(loop_point_manifolds, holonomy_manifolds, subgraphs, pos, save_path, dataset, ranks, wrt=wrt)\n",
    "    #if plot_group:\n",
    "    #    _plot_holonomy_group(transformation_matrix, holonomy_manifolds, ranks, save_path, wrt=wrt)\n",
    "    return transformation_matrix, holonomy_manifolds, ranks, save_path, wrt\n",
    "\n",
    "\n",
    "def holonomy(manifold, metric, form, surface, mappable_dict, rank, num_cycles=10000):\n",
    "    \"\"\"\n",
    "    Compute the holonomy of a given manifold with respect to a given metric and surface.\n",
    "    \n",
    "    Parameters:\n",
    "    - manifold: networkx.Graph, representing the manifold\n",
    "    - metric: numpy array, representing the metric tensor at each point on the manifold\n",
    "    - christoffel: numpy array, representing the christoffel tensor at each point on the manifold\n",
    "    - surface: numpy array, representing the surface at each point on the manifold\n",
    "    - mappable_dict: dict, mapping the indices of the points on the manifold to the indices of the points on the surface\n",
    "    - rank: int, representing the rank of the manifold\n",
    "    - num_cycles: int, representing the number of cycles to compute\n",
    "\n",
    "    Returns:\n",
    "    - holonomy: numpy array, representing the holonomy of the manifold\n",
    "    \"\"\"\n",
    "    # Normalise the metric tensor\n",
    "    eigenvectors, g_tilde, dg_tilde = filter_eigs(metric, form, rank)\n",
    "    surface_proj = np.einsum('nij, nj -> ni', eigenvectors, surface)\n",
    "    # Compute the Christoffel symbols of the reduced metric\n",
    "    g_inv = np.linalg.inv(g_tilde)\n",
    "    christoffel_tilde = batch_vectorised_christoffel_symbols(g_inv, dg_tilde)\n",
    "    holonomy_manifold = []\n",
    "    manifold_loop_points = []\n",
    "    transformation_manifold = []\n",
    "    cycles = find_cycles_random_walk(manifold, num_cycles=num_cycles)\n",
    "    for cycle in tqdm(cycles):\n",
    "        full_loop = cycle + [cycle[0]]\n",
    "        points_path = surface_proj[[mappable_dict[p] for p in full_loop]]\n",
    "        christoffel_path = christoffel_tilde[[mappable_dict[p] for p in full_loop]]\n",
    "        start_vectors_path = eigenvectors[[mappable_dict[full_loop[0]]]]\n",
    "        if rank != 1:\n",
    "            start_vectors_path = start_vectors_path.squeeze()\n",
    "\n",
    "        transformation_matrix = np.zeros_like(start_vectors_path.T)\n",
    "        for indx, start_vector in enumerate(start_vectors_path.T):\n",
    "            transport_vector = parallel_transport(points_path, start_vector, christoffel_path)\n",
    "            #print(\"Shape of transport_vector:\", transport_vector.shape)\n",
    "            #print(\"Shape of transport_vector:\", transport_vector.squeeze().shape)\n",
    "            #print(\"Shape of transformation_matrix:\", transformation_matrix[:, indx].shape)\n",
    "            if rank == 1:\n",
    "                transformation_matrix[indx] = np.array([transport_vector])\n",
    "            else:\n",
    "                transformation_matrix[indx] = transport_vector\n",
    "            angle_diff = (np.dot(transport_vector, start_vector) / (np.linalg.norm(transport_vector) * np.linalg.norm(start_vector))).squeeze()\n",
    "            holonomy_manifold.append(angle_diff)\n",
    "            manifold_loop_points.append(full_loop[0])\n",
    "        if rank != 1:\n",
    "            transformation_matrix = start_vectors_path @ transformation_matrix\n",
    "        else:\n",
    "            transformation_matrix = (start_vectors_path.squeeze() @ transformation_matrix.squeeze()).reshape(1,1)\n",
    "        transformation_manifold.append(transformation_matrix)\n",
    "\n",
    "    return holonomy_manifold, manifold_loop_points, transformation_manifold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "mode=\"disentangled\"\n",
    "model_name = \"vae\"\n",
    "size = \"disentangled_5\"\n",
    "epoch = 1900\n",
    "\n",
    "\n",
    "models_path = f\"../../../models/unsupervised/{model_name}/saved_models\"\n",
    "res_q_25, res_med, res_q_75 = [], [], []\n",
    "with open(f'{models_path}/{size}/dataset.pkl', 'rb') as f:\n",
    "\tdataset = pkl.load(f)\n",
    "\n",
    "features = [64, 32, 16, 8 ,4]\n",
    "encoder = Encoder(in_features=32, features=features, out_features=2)\n",
    "decoder = Decoder(in_features=2, features=list(reversed(features)), out_features=32)\n",
    "model = VAE(encoder, decoder)\n",
    "\n",
    "model.load_state_dict(torch.load(f\"{models_path}/{size}/model_{epoch}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3 nearest neighbors\n",
      "Jacobian computed in 0.12490177154541016 seconds\n",
      "Jacobian converted to numpy in 0.001081228256225586 seconds\n",
      "Pullback metric computed in 0.007870912551879883 seconds\n",
      "Pullback differential computed in 0.4119439125061035 seconds\n",
      "Pullback Ricci computed in 0.008700847625732422 seconds\n",
      "Pulled back\n",
      "K=2 -> 127\n",
      "Nodes remaining: {2, 116}\n",
      "K=3 -> 36\n",
      "Nodes remaining: {42, 380, 378}\n",
      "K=4 -> 5\n",
      "Nodes remaining: {1, 2, 9, 51, 116, 21, 246, 22, 308, 156, 349}\n",
      "Rank 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:33<00:00, 295.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:29<00:00, 341.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:36<00:00, 274.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:29<00:00, 340.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:35<00:00, 285.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:39<00:00, 256.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:36<00:00, 276.58it/s]\n"
     ]
    }
   ],
   "source": [
    "sigma = 0.1\n",
    "quantile = 0.9\n",
    "tol = 1e-5\n",
    "save_path = f\"figures/{model_name}/{mode}/{size}/{epoch}\"\n",
    "N = 20\n",
    "transformation_matrix, holonomy_manifolds, ranks, save_path, wrt = main(model, dataset, N, sigma, quantile, tol, save_path, MIN_SIZE=10, wrt=\"output_wise\", plot_hol=True, plot_graph=False, plot_group=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/x8lg97sd7512c9qf07myy77m0000gn/T/ipykernel_23639/2279385847.py:285: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sine_angle = np.sqrt(1 - loop ** 2)  # Since sin^2(theta) + cos^2(theta) = 1\n",
      "/Users/maxpowers/miniconda3/envs/DL/lib/python3.10/site-packages/numpy/lib/histograms.py:852: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  indices = f_indices.astype(np.intp)\n",
      "/Users/maxpowers/miniconda3/envs/DL/lib/python3.10/site-packages/matplotlib/axes/_axes.py:6793: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  bins = np.array(bins, float)  # causes problems if float16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Set font size for plots\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.tight_layout()\n",
    "_plot_holonomy_group(transformation_matrix, holonomy_manifolds, ranks, save_path, wrt=wrt)\n",
    "_plot_hol(holonomy_manifolds, save_path, ranks, wrt=wrt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
