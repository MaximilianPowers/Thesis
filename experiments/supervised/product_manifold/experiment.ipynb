{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import pickle as pkl\n",
    "sys.path.append('../../../')\n",
    "\n",
    "from experiments.supervised.product_manifold.script import main, _plot_clusters, _plot_holonomy_dist, _plot_holonomy_surface\n",
    "from models.supervised.mlp.model import MLP\n",
    "\n",
    "models_path = \"../../../models/supervised/mlp/saved_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x Layer(\n",
       "      (act_func): Tanh()\n",
       "      (linear_map): Linear(in_features=2, out_features=2, bias=True)\n",
       "    )\n",
       "    (6): Layer(\n",
       "      (act_func): Sigmoid()\n",
       "      (linear_map): Linear(in_features=2, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = \"underfit\"\n",
    "mode = \"moon\"\n",
    "epoch = 199\n",
    "model = MLP(2,7,2,2)\n",
    "with open(f'{models_path}/2_wide/mlp_{mode}/dataset.pkl', 'rb') as f:\n",
    "\tdataset = pkl.load(f)\n",
    "\n",
    "full_path = f'{models_path}/{size}/mlp_{mode}/model_{epoch}.pth'\n",
    "model.load_state_dict(torch.load(full_path))\n",
    "if size == \"overfit\":\n",
    "\tmodel.num_layers -= 1\n",
    "\tmodel.layers = model.layers[:-1]\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering took 2.6322848796844482 seconds. Best score: 0.9903528094291687. Best config: {'eps': 0.1619216223418936, 'min_samples': 6}\n",
      "Finding cycles took 0.29749584197998047 seconds\n",
      "Computing holonomy group took 0.8020906448364258 seconds. 0.0002406512585767854 seconds per cycle\n",
      "Finding cycles took 0.19490265846252441 seconds\n",
      "Computing holonomy group took 0.7408199310302734 seconds. 0.000222268206129695 seconds per cycle\n",
      "Finding cycles took 0.2003629207611084 seconds\n",
      "Computing holonomy group took 0.7663149833679199 seconds. 0.00022991748675905188 seconds per cycle\n"
     ]
    }
   ],
   "source": [
    "wrt = \"layer_wise\"\n",
    "N=50\n",
    "sigma = 0.05\n",
    "X = torch.tensor(dataset.X).float()\n",
    "holonomy_manifold, start_loop_vectors, loop_points = main(model, X, N, sigma, 0.9, wrt=wrt, K_MAX=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_holonomy_surface(holonomy_manifold, loop_points, X, dataset.y, mode, size, wrt, epoch)\n",
    "_plot_clusters(holonomy_manifold, loop_points, X, dataset.y, mode, size, wrt, epoch)\n",
    "_plot_holonomy_dist(holonomy_manifold, mode, size, wrt, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
